# JetRacer 技術仕様書

## 概要

【客観】
JetRacerは、NVIDIA Jetson Nanoを搭載した小型自律走行車です。機械学習とコンピュータビジョンを活用し、障害物回避や自律走行を実現します。

【やなの視点】
- 走らせながら学べる最高の教材！まずは動かしてみよう
- Jetson Nanoのパワーで本格的なAI走行ができる

【あゆの視点】
- 限られたリソースで最大効果を出す設計が求められる
- 電力効率と処理性能のバランスを常に意識する必要がある

## ハードウェア構成

### プラットフォーム

【客観】
- ベース: NVIDIA Jetson Nano（4GB RAM）
- CPU: Quad-core ARM Cortex-A57
- GPU: 128-core NVIDIA Maxwell GPU
- 電源: 2セルLiPoバッテリー（7.4V）

【やなの視点】
- GPUが128コアもあるから画像処理は任せとけ！
- バッテリーは7.4Vで30分は走れる

【あゆの視点】
- 4GB RAMは制約。モデルサイズと推論速度のトレードオフを計測すべき
- バッテリー電圧は6.5V以下で危険領域。走行前に必ず確認

### センサー類

【客観】
- **超音波センサー（3個）**
  - 前方センサー: HC-SR04（測定範囲: 2cm - 400cm）
  - 左センサー: HC-SR04（測定範囲: 2cm - 400cm）
  - 右センサー: HC-SR04（測定範囲: 2cm - 400cm）
  - 精度: ±3mm
  - 測定周期: 約50ms

- **IMU（慣性計測装置）**
  - モデル: MPU6050
  - 3軸加速度センサー
  - 3軸ジャイロスコープ
  - サンプリングレート: 最大8kHz

- **カメラ**
  - 型番: IMX219 カメラモジュール
  - 解像度: 8MP（3280 x 2464）
  - フレームレート: 30fps @ 1080p
  - 視野角: 約160度

【やなの視点】
- 超音波は素直で使いやすい。まずこれで障害物検知を試そう
- カメラは160度の広角！視野が広いから見逃しにくい

【あゆの視点】
- 超音波の50ms周期は20Hzに相当。高速走行時は検知遅れに注意
- IMUのキャリブレーションは必須。ドリフト補正なしでは精度が劣化する

### アクチュエータ

【客観】
- **DCモーター**
  - 駆動方式: 4WD（四輪駆動）
  - モータードライバ: TB6612FNG
  - 最大出力: 1.2A（連続）、3.2A（ピーク）

- **サーボモーター**
  - 型番: SG90
  - 動作角度: 0° - 180°
  - 制御方式: PWM信号
  - 応答速度: 0.1秒/60度

【やなの視点】
- 4WDだからパワフル！多少の段差も乗り越えられる
- サーボは0.1秒で反応するから、直感的に操作できる

【あゆの視点】
- ピーク電流3.2Aはバッテリー負荷が大きい。連続急加速は避けるべき
- サーボのPWM周波数と制御ループの同期を確認すること

## ソフトウェア構成

### オペレーティングシステム

【客観】
- Ubuntu 18.04 LTS（JetPack SDK付属）
- Python 3.6以上

### 主要ライブラリ

【客観】
- **PyTorch**: 深層学習フレームワーク
- **OpenCV**: 画像処理
- **Adafruit_PCA9685**: サーボ制御
- **Jetson.GPIO**: GPIO制御

【やなの視点】
- PyTorchは直感的！モデルを試すのが楽しい
- OpenCVでリアルタイム画像処理ができる

【あゆの視点】
- PyTorchのメモリ使用量を監視すべき。OOMは致命的
- ライブラリのバージョン互換性を事前に検証すること

### 走行モード

#### 1. センサーオンリーモード（SENSOR_ONLY）

【客観】
超音波センサーのみで障害物を回避。

**動作原理**:
- 前方センサーが50cm以下を検知 → 減速
- 前方センサーが30cm以下を検知 → 停止
- 左右センサーで障害物の位置を判断 → 回避方向決定

**性能特性**:
- 低負荷（CPU使用率: 約20%）
- 反応速度が速い（応答時間: 約100ms）
- 複雑な環境では対応困難
- 視覚情報がない

【やなの視点】
- 初心者はまずこれから！シンプルで動きがわかりやすい
- 電力消費も少ないから長時間テストに最適

【あゆの視点】
- CPU使用率20%は余裕がある。他の処理と並行可能
- ただし超音波だけでは透明な障害物は検知不可。限界を理解すること

#### 2. ビジョンモード（VISION）

【客観】
カメラ画像を解析して走行。

**動作原理**:
- カメラ画像から車線を検出
- 深層学習モデルで操舵角を予測
- センサー情報も併用して安全性向上

**性能特性**:
- 複雑な環境に対応
- 人間の運転に近い挙動
- 高負荷（CPU使用率: 約60%, GPU使用率: 約80%）
- 照明条件に影響される

【やなの視点】
- これが本命！AIで走る醍醐味を味わえる
- カメラが見てるものを可視化すると面白い

【あゆの視点】
- GPU使用率80%は危険域。温度監視とスロットリング対策が必要
- 照明変化に弱いので、学習データに多様な条件を含めること

#### 3. 完全自律モード（FULL_AUTONOMY）

【客観】
センサー + ビジョンの統合制御。

**動作原理**:
- カメラで進路判断
- 超音波センサーで安全確認
- IMUで姿勢制御
- 複数の情報を統合して最適な制御を実行

【やなの視点】
- 全部使って走る究極モード！信頼性も最高
- でも複雑だから、まずは部分的に試してから統合しよう

【あゆの視点】
- センサーフュージョンの遅延を最小化することが鍵
- 矛盾する情報が来た時の優先順位を明確に定義すること

## 制御パラメータ

### スロットル（速度）

【客観】
- 範囲: -1.0 〜 +1.0
  - -1.0: 最大後退
  - 0.0: 停止
  - +1.0: 最大前進
- 推奨値: 0.3 - 0.7（安定走行）
- 最高速度: 約3.0 m/s（スロットル1.0時）

【やなの視点】
- 0.5くらいから始めて、慣れたら上げていこう
- 最高速度3m/sは結構速い！室内では0.3で十分

【あゆの視点】
- スロットル0.7以上はバッテリー消費が急増。走行時間に影響
- 速度と制動距離の関係を把握しておくこと

### ステアリング（操舵）

【客観】
- 範囲: -1.0 〜 +1.0
  - -1.0: 最大右旋回
  - 0.0: 直進
  - +1.0: 最大左旋回
- 旋回半径: 約0.5m（最大舵角時）

### PIDパラメータ（速度制御）

【客観】
- P（比例）ゲイン: 0.5
- I（積分）ゲイン: 0.1
- D（微分）ゲイン: 0.05

【やなの視点】
- PIDのデフォルト値でまず試す。調整は後から
- Pゲインが一番効くから、ここから調整

【あゆの視点】
- I項の積分飽和に注意。アンチワインドアップを実装すべき
- D項はノイズに敏感。フィルタリングを検討

## 安全機能

### 緊急停止条件

【客観】
1. 前方センサーが20cm以下を検知
2. バッテリー電圧が6.5V以下
3. IMUで異常な姿勢を検出（転倒など）
4. 通信断（2秒以上）

【やなの視点】
- 安全第一！緊急停止は絶対に機能するようにしておく
- 20cmで止まれば大体ぶつからない

【あゆの視点】
- 緊急停止の応答時間を実測すること。仕様通りか検証が必要
- 複数条件の優先順位とタイムアウト値を文書化すべき

### フェールセーフ

【客観】
- センサー故障時: センサーオンリーモードに自動切替
- カメラ故障時: ビジョンモード無効化
- バッテリー低下時: 低速モード（スロットル上限0.3）

## 性能指標

### 走行性能

【客観】
- 最高速度: 3.0 m/s
- 最小旋回半径: 0.5 m
- 登坂能力: 約15度
- 連続走行時間: 約30分（通常走行時）

### 処理性能

【客観】
- カメラフレーム処理: 30fps
- 深層学習推論速度: 約50ms/フレーム
- センサーサンプリング: 20Hz
- 制御ループ周期: 50Hz（20ms）

【やなの視点】
- 50ms推論は十分速い！リアルタイムに感じる
- 30fps出てれば映像もスムーズ

【あゆの視点】
- 推論50msと制御20msの非同期処理を適切に設計すること
- フレームドロップ時の補間処理を検討すべき

## トラブルシューティング

### よくある問題

【客観】
**問題1: カメラ映像が表示されない**
- 原因: カメラケーブルの接続不良
- 解決: カメラケーブルを再接続、Jetson Nanoを再起動

**問題2: モーターが動かない**
- 原因: バッテリー電圧低下、またはモータードライバの過熱
- 解決: バッテリー充電、5分間冷却後に再起動

**問題3: 直進しない**
- 原因: 左右モーターの出力差、またはタイヤの摩耗
- 解決: trim値を調整（config.yamlのsteering_offset）

**問題4: センサー値が不安定**
- 原因: 配線のノイズ、または電源電圧の変動
- 解決: 配線を短くする、コンデンサで電源安定化

## メンテナンス

### 日常点検

【客観】
- バッテリー電圧の確認（7.0V以上）
- タイヤの摩耗チェック
- センサー表面の清掃
- カメラレンズの汚れ確認

【やなの視点】
- 走る前にバッテリーだけは絶対チェック！
- タイヤが減ってきたら早めに交換

【あゆの視点】
- 点検結果をログに残すと劣化傾向を把握できる
- センサー清掃は性能に直結。定期的に実施すること

### 定期メンテナンス（100時間ごと）

【客観】
- モーターブラシの点検
- ギアの摩耗確認
- ベアリングへの注油
- 配線の断線チェック

## 参考情報

### 公式リソース

【客観】
- NVIDIA JetRacer Wiki: https://github.com/NVIDIA-AI-IOT/jetracer
- Jetson Nano 開発者ガイド: https://developer.nvidia.com/jetson-nano

### コミュニティ
- JetBot/JetRacer Forums
- NVIDIA Developer Forums

---
**ドキュメント作成日**: 2026年1月14日
**対象バージョン**: JetRacer v1.0
**duo-talk-simple プロジェクト用知識ベース**
**Phase 2B**: 視点マーカー追加済み
