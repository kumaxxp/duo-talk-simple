# テスト戦略（TDD方式）

**開発方針**: テスト駆動開発（Test-Driven Development）

**原則**: **テストファースト - 実装は全てテストから始まる**

---

## TDD の基本理念

### Red-Green-Refactor サイクル

```
┌─────────────────────────────────────────┐
│ 1. RED（失敗）                          │
│    - 失敗するテストを書く                │
│    - 何を実装すべきか明確にする          │
└─────────────┬───────────────────────────┘
              ↓
┌─────────────────────────────────────────┐
│ 2. GREEN（成功）                        │
│    - テストを通す最小限のコードを書く    │
│    - 品質より速度優先                    │
└─────────────┬───────────────────────────┘
              ↓
┌─────────────────────────────────────────┐
│ 3. REFACTOR（改善）                     │
│    - コードを整理・最適化                │
│    - テスト成功を維持しながら改善        │
└─────────────┬───────────────────────────┘
              ↓
              次のテストへ
```

### TDD の利点（duo-talk-simpleでの適用）

| 利点 | duo-talk での具体例 |
|------|-------------------|
| **仕様の明確化** | API仕様がテストコードで定義される |
| **リグレッション防止** | 修正時に既存機能が壊れない |
| **リファクタリング安全性** | テスト成功=動作保証 |
| **デバッグ時間削減** | どこが壊れたか即座に判明 |
| **ドキュメント代替** | テストコード=使用例 |
| **設計改善** | テスタブルな設計=良い設計 |

---

## テストレベル構成

### 1. ユニットテスト（個別コンポーネント）

**対象**:
- `core/ollama_client.py`
- `core/rag_engine.py`
- `core/character.py`

**目的**: 各クラスの振る舞いを独立してテスト

**実行頻度**: コード変更毎（自動）

**テスト数**: 各クラス5-10件

### 2. 統合テスト（コンポーネント連携）

**対象**:
- OllamaClient ↔ RAGEngine
- RAGEngine ↔ Character
- 全体フロー（chat.py）

**目的**: コンポーネント間の連携確認

**実行頻度**: Phase完了毎

**テスト数**: 3-5件

### 3. パフォーマンステスト

**対象**:
- 応答時間
- 検索速度
- メモリ使用量

**目的**: 性能要件の充足確認

**実行頻度**: 統合完了後

**テスト数**: 3-5件

### 4. 手動受け入れテスト

**対象**:
- キャラクター性の確認
- 自然な会話フロー
- エラー時の振る舞い

**目的**: ユーザー体験の確認

**実行頻度**: リリース前

**所要時間**: 30分

---

## テストケース設計原則

### FIRST 原則

| 原則 | 説明 | duo-talk での適用 |
|------|------|------------------|
| **Fast** | 高速実行 | 1テスト < 1秒、全体 < 30秒 |
| **Independent** | 独立性 | テスト間で状態共有しない |
| **Repeatable** | 再現可能 | いつ実行しても同じ結果 |
| **Self-Validating** | 自己検証 | Pass/Fail が明確 |
| **Timely** | タイムリー | 実装前にテスト作成 |

### Given-When-Then パターン

```python
def test_example():
    # Given（前提条件）
    client = OllamaClient()
    messages = [{"role": "user", "content": "こんにちは"}]
    
    # When（実行）
    response = client.generate(messages)
    
    # Then（検証）
    assert len(response) > 0
    assert isinstance(response, str)
```

---

## テストダブル戦略

### モック不使用の方針

**理由**:
- Ollamaは実際に動作するローカルサーバー
- モックより実環境テストが信頼性高い
- CLIアプリケーションでモックは過剰

**例外**:
- Ollama未起動時のテスト（エラーハンドリング確認）
- ネットワークエラーのシミュレーション

### フィクスチャ活用

```python
# tests/conftest.py

import pytest
import shutil
import os
from core.ollama_client import OllamaClient
from core.rag_engine import RAGEngine

@pytest.fixture(scope="session")
def ollama_client():
    """セッション全体で共有するOllamaClient"""
    return OllamaClient()

@pytest.fixture(scope="function")
def rag_engine(ollama_client):
    """各テストで独立したRAGEngine"""
    test_path = "./data/test_chroma_db"
    
    if os.path.exists(test_path):
        shutil.rmtree(test_path)
    
    rag = RAGEngine(ollama_client, chroma_path=test_path)
    
    yield rag
    
    # クリーンアップ
    if os.path.exists(test_path):
        shutil.rmtree(test_path)
```

---

## テストケース一覧

### Phase 1: OllamaClient

| テストID | テスト名 | 目的 | 期待結果 |
|---------|---------|------|---------|
| TC-O-001 | test_init | 初期化 | 属性が正しく設定 |
| TC-O-002 | test_is_healthy | 接続確認 | True返却 |
| TC-O-003 | test_generate_basic | 基本生成 | 文字列返却 |
| TC-O-004 | test_generate_with_params | パラメータ生成 | 指定温度で生成 |
| TC-O-005 | test_embed_basic | 基本埋め込み | 1024次元ベクトル |
| TC-O-006 | test_retry_mechanism | リトライ | 3回試行後例外 |
| TC-O-007 | test_timeout | タイムアウト | 指定秒数で例外 |

**実装サンプル**: [07_実装サンプル.md - OllamaClientテスト](./07_実装サンプル.md#ollamaclientテスト)

### Phase 2: RAGEngine

| テストID | テスト名 | 目的 | 期待結果 |
|---------|---------|------|---------|
| TC-R-001 | test_init | 初期化 | コレクション作成 |
| TC-R-002 | test_add_knowledge | 知識追加 | count増加 |
| TC-R-003 | test_search_basic | 基本検索 | 関連知識返却 |
| TC-R-004 | test_search_with_filter | フィルタ検索 | メタデータ絞込 |
| TC-R-005 | test_search_accuracy | 検索精度 | score > 0.5 |
| TC-R-006 | test_chunk_text | テキスト分割 | 適切にチャンク化 |
| TC-R-007 | test_init_from_files | ファイル投入 | 全ファイル読込 |
| TC-R-008 | test_empty_search | 空検索 | 空リスト返却 |

**実装サンプル**: [07_実装サンプル.md - RAGEngineテスト](./07_実装サンプル.md#ragengineテスト)

### Phase 3: Character

| テストID | テスト名 | 目的 | 期待結果 |
|---------|---------|------|---------|
| TC-C-001 | test_init | 初期化 | YAML読込成功 |
| TC-C-002 | test_respond_basic | 基本応答 | 文字列返却 |
| TC-C-003 | test_respond_with_rag | RAG統合 | 知識参照確認 |
| TC-C-004 | test_history_management | 履歴管理 | 正しく保存 |
| TC-C-005 | test_clear_history | 履歴クリア | 空になる |
| TC-C-006 | test_query_rewrite | クエリ書換 | 代名詞解消 |
| TC-C-007 | test_max_history_limit | 履歴上限 | 10ターンで固定 |

**実装サンプル**: [07_実装サンプル.md - Characterテスト](./07_実装サンプル.md#characterテスト)

### Phase 4: 統合テスト

| テストID | テスト名 | 目的 | 期待結果 |
|---------|---------|------|---------|
| TC-I-001 | test_full_flow | 全体フロー | 起動→応答成功 |
| TC-I-002 | test_character_switch | キャラ切替 | やな↔あゆ動作 |
| TC-I-003 | test_multi_turn | 複数ターン | 5ターン会話 |
| TC-I-004 | test_rag_context | RAG文脈 | 知識参照確認 |
| TC-I-005 | test_config_loading | 設定読込 | config.yaml反映 |

**実装サンプル**: [07_実装サンプル.md - 統合テスト](./07_実装サンプル.md#統合テスト)

### Phase 5: パフォーマンステスト

| テストID | テスト名 | 目的 | 期待結果 |
|---------|---------|------|---------|
| TC-P-001 | test_response_time | 応答時間 | < 5秒 |
| TC-P-002 | test_rag_search_time | 検索時間 | < 0.5秒 |
| TC-P-003 | test_embedding_time | 埋め込み時間 | < 0.2秒 |
| TC-P-004 | test_startup_time | 起動時間 | 初回 < 30秒 |

**実装サンプル**: [07_実装サンプル.md - パフォーマンステスト](./07_実装サンプル.md#パフォーマンステスト)

---

## テスト自動化

### 1. ローカル開発環境

#### ファイル監視モード

```bash
# pytest-watch インストール
pip install pytest-watch

# 監視モード起動
ptw -- tests/ -v
```

**動作**:
- ファイル保存時に自動でテスト実行
- TDDサイクルが高速化

#### pre-commit フック

```bash
# pre-commit インストール
pip install pre-commit

# 設定
cat > .pre-commit-config.yaml << EOF
repos:
  - repo: local
    hooks:
      - id: pytest
        name: pytest
        entry: pytest tests/ -v
        language: system
        pass_filenames: false
        always_run: true
EOF

# 有効化
pre-commit install
```

**動作**:
- git commit 時に自動でテスト実行
- テスト失敗時はコミット中断

### 2. CI/CD パイプライン

#### GitHub Actions 設定

```yaml
# .github/workflows/test.yml

name: Test Suite

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest-cov
      
      - name: Run tests
        run: |
          pytest tests/ -v \
            --cov=core \
            --cov-report=xml \
            --cov-report=term-missing \
            --cov-fail-under=80
      
      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          fail_ci_if_error: true
```

**特徴**:
- プッシュ・PRで自動実行
- カバレッジ80%未満で失敗
- codecov連携

### 3. カバレッジ監視

#### カバレッジレポート生成

```bash
# HTML レポート
pytest tests/ --cov=core --cov-report=html
open htmlcov/index.html

# ターミナル表示
pytest tests/ --cov=core --cov-report=term-missing

# 最低カバレッジ指定
pytest tests/ --cov=core --cov-fail-under=80
```

#### カバレッジ目標

| コンポーネント | 目標カバレッジ | 理由 |
|--------------|--------------|------|
| OllamaClient | > 90% | 外部依存少ない |
| RAGEngine | > 85% | ChromaDB依存 |
| Character | > 80% | LLM応答の不確実性 |
| **全体** | **> 80%** | **品質基準** |

---

## テスト実行戦略

### 開発フェーズ別実行方針

#### 開発中（TDDサイクル）

```bash
# 特定のテストのみ実行（高速）
pytest tests/test_ollama_client.py -v

# ファイル監視モード
ptw -- tests/test_ollama_client.py -v
```

**頻度**: 数分毎

#### Phase完了時

```bash
# 該当Phaseの全テスト
pytest tests/test_ollama_client.py tests/test_rag_engine.py -v

# カバレッジ確認
pytest tests/test_ollama_client.py --cov=core.ollama_client
```

**頻度**: Phase完了毎

#### 統合前

```bash
# 全ユニットテスト
pytest tests/test_*.py -v --ignore=tests/test_integration.py

# カバレッジ確認
pytest tests/ --cov=core --cov-report=term-missing
```

**頻度**: Phase 4 開始前

#### リリース前

```bash
# 全テスト（統合+パフォーマンス含む）
pytest tests/ -v --cov=core --cov-fail-under=80

# 手動受け入れテスト
python chat.py
```

**頻度**: リリース前

### 並列実行による高速化

```bash
# pytest-xdist インストール
pip install pytest-xdist

# CPUコア数分並列実行
pytest tests/ -n auto

# 4コア指定
pytest tests/ -n 4
```

**効果**: テスト実行時間が約1/4に短縮

---

## テスト品質基準

### 必須条件（リリースブロッカー）

- [ ] **全テスト成功**（100% Pass）
- [ ] **カバレッジ > 80%**
- [ ] **パフォーマンステスト合格**
- [ ] **CI/CDパイプライン成功**

### 推奨条件

- [ ] コードカバレッジ > 85%
- [ ] ブランチカバレッジ > 75%
- [ ] テスト実行時間 < 30秒
- [ ] 手動受け入れテスト完了

---

## TDD ベストプラクティス

### 1. テスト命名規則

```python
def test_{対象メソッド}_{条件}_{期待結果}():
    """
    例:
    - test_generate_with_invalid_input_raises_error
    - test_search_with_empty_query_returns_empty_list
    - test_respond_maintains_history_after_multiple_turns
    """
```

### 2. Arrange-Act-Assert パターン

```python
def test_example():
    # Arrange（準備）
    client = OllamaClient()
    messages = [{"role": "user", "content": "test"}]
    
    # Act（実行）
    response = client.generate(messages)
    
    # Assert（検証）
    assert len(response) > 0
```

### 3. 1テスト1アサーション（原則）

```python
# Good
def test_response_is_string():
    response = client.generate(messages)
    assert isinstance(response, str)

def test_response_is_not_empty():
    response = client.generate(messages)
    assert len(response) > 0

# Acceptable（関連する検証）
def test_response_format():
    response = client.generate(messages)
    assert isinstance(response, str)
    assert len(response) > 0
```

### 4. エッジケースのテスト

```python
# 正常系
def test_generate_normal_case():
    ...

# エッジケース
def test_generate_empty_message():
    ...

def test_generate_very_long_message():
    ...

def test_generate_special_characters():
    ...
```

### 5. エラーケースのテスト

```python
def test_generate_with_connection_error():
    client = OllamaClient(base_url="http://invalid:11434/v1")
    with pytest.raises(ConnectionError):
        client.generate(messages)

def test_generate_with_timeout():
    client = OllamaClient(timeout=0.1)
    with pytest.raises(TimeoutError):
        client.generate(very_complex_messages)
```

---

## デバッグ戦略

### テスト失敗時のフロー

```
1. エラーメッセージ確認
   ↓
2. 該当テストのみ実行
   pytest tests/test_xxx.py::test_yyy -v
   ↓
3. pdb デバッガ起動
   pytest tests/test_xxx.py::test_yyy -v --pdb
   ↓
4. 原因特定
   ↓
5. 修正
   ↓
6. 全テスト実行
   pytest tests/ -v
```

### デバッグツール

```bash
# pdb デバッガ
pytest tests/test_xxx.py --pdb

# 詳細出力
pytest tests/test_xxx.py -vv

# 標準出力表示
pytest tests/test_xxx.py -s

# 最初の失敗で停止
pytest tests/ -x

# 失敗したテストのみ再実行
pytest tests/ --lf
```

---

## 手動受け入れテスト

### テストシナリオ

#### シナリオ1: やなとの基本会話

```
1. システム起動
2. キャラクター選択: yana
3. 挨拶: "こんにちは"
   → カジュアルな挨拶を返す
4. 技術質問: "JetRacerって何？"
   → 技術知識を参照して説明
5. 追加質問: "センサーは？"
   → 文脈を理解して答える
6. 終了: /exit
```

#### シナリオ2: キャラクター切替

```
1. システム起動
2. やな選択 → 会話
3. /switch
4. あゆ選択 → 会話
   → 口調の違いを確認
```

#### シナリオ3: エラーハンドリング

```
1. Ollama停止状態で起動
   → 適切なエラーメッセージ
2. 不正なコマンド入力
   → エラーメッセージ + 継続可能
```

### チェックリスト

- [ ] やなの口調: カジュアル
- [ ] あゆの口調: 丁寧
- [ ] 技術知識の正確性
- [ ] 文脈の維持
- [ ] エラー時の動作
- [ ] コマンド動作（/clear, /exit）

---

## 継続的改善

### テスト追加タイミング

1. **バグ発見時**: バグ再現テストを追加 → 修正 → テスト成功
2. **新機能追加時**: テスト作成 → 実装
3. **リファクタリング時**: 既存テスト維持 → リファクタ
4. **コードレビュー時**: カバレッジ確認 → 不足分追加

### メトリクス収集

```bash
# テスト実行時間の記録
pytest tests/ --durations=10

# カバレッジ推移の記録
pytest tests/ --cov=core --cov-report=json
```

---

**作成日**: 2026年1月14日  
**最終更新**: 2026年1月14日（TDD戦略に変更、実装コードを07に分離）  
**実装サンプル**: [07_実装サンプル.md](./07_実装サンプル.md)
