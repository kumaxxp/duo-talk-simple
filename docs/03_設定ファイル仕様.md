# 設定ファイル仕様

## 1. config.yaml（全体設定）

### 1.1 ファイル概要

**パス**: `duo-talk-simple/config.yaml`

**責務**: システム全体の動作を制御する設定を一元管理

**設計思想**:
- 実装を変えずに動作変更可能
- モデル切り替えが容易
- 環境に応じたカスタマイズ

### 1.2 完全な設定例

```yaml
# duo-talk-simple/config.yaml

# ==========================================
# Ollama設定
# ==========================================
ollama:
  # Ollama API URL
  base_url: "http://localhost:11434/v1"
  
  # 使用するLLMモデル
  llm_model: "gemma3:12b"
  
  # 埋め込みモデル
  embedding_model: "mxbai-embed-large"
  
  # タイムアウト時間（秒）
  timeout: 30.0
  
  # リトライ回数
  max_retries: 3
  
  # 生成パラメータ
  generation:
    temperature: 0.7        # 生成の多様性（0.0-2.0）
    max_tokens: 2000        # 最大生成トークン数
    top_p: 0.9              # nucleus sampling
    top_k: 40               # top-k sampling

# ==========================================
# RAG設定
# ==========================================
rag:
  # ChromaDB永続化パス
  chroma_db_path: "./data/chroma_db"
  
  # コレクション名
  collection_name: "duo_knowledge"
  
  # 検索設定
  search:
    top_k: 3                # 取得件数
    min_score: 0.5          # 最低類似度スコア
  
  # チャンク分割設定
  chunking:
    max_chars: 1000         # 最大文字数
    overlap: 100            # オーバーラップ文字数
  
  # Query Rewrite機能
  enable_query_rewrite: false  # デフォルトはOFF（シンプルに）

# ==========================================
# キャラクター設定
# ==========================================
characters:
  yana:
    config: "./personas/yana.yaml"
    enabled: true
  
  ayu:
    config: "./personas/ayu.yaml"
    enabled: true

# ==========================================
# 知識ベース設定
# ==========================================
knowledge:
  # 知識ソースディレクトリ
  source_dir: "./knowledge"
  
  # ファイルとメタデータのマッピング
  sources:
    - file: "jetracer_tech.txt"
      metadata:
        domain: "technical"
        character: "both"
        importance: "high"
    
    - file: "autonomy_basics.txt"
      metadata:
        domain: "technical"
        character: "both"
        importance: "medium"
    
    - file: "sisters_shared.txt"
      metadata:
        domain: "character"
        character: "both"
        importance: "high"

# ==========================================
# ログ設定
# ==========================================
logging:
  level: "INFO"             # DEBUG, INFO, WARNING, ERROR, CRITICAL
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "./logs/duo-talk.log"
  console: true

# ==========================================
# パフォーマンス設定
# ==========================================
performance:
  # 埋め込み生成時のバッチサイズ
  embedding_batch_size: 10
  
  # 会話履歴保持ターン数
  max_history_turns: 10

# ==========================================
# 開発・デバッグ設定
# ==========================================
debug:
  # 詳細ログ出力
  verbose: false
  
  # 応答時間測定
  measure_latency: true
  
  # RAG検索結果を表示
  show_rag_results: false
```

### 1.3 設定項目詳細

#### ollama セクション

| 項目 | 型 | デフォルト | 説明 |
|------|-----|-----------|------|
| base_url | string | "http://localhost:11434/v1" | Ollama API URL |
| llm_model | string | "gemma3:12b" | 使用するLLMモデル |
| embedding_model | string | "mxbai-embed-large" | 埋め込みモデル |
| timeout | float | 30.0 | タイムアウト（秒） |
| max_retries | int | 3 | リトライ回数 |
| generation.temperature | float | 0.7 | 生成の多様性 |
| generation.max_tokens | int | 2000 | 最大トークン数 |

#### rag セクション

| 項目 | 型 | デフォルト | 説明 |
|------|-----|-----------|------|
| chroma_db_path | string | "./data/chroma_db" | ChromaDBパス |
| collection_name | string | "duo_knowledge" | コレクション名 |
| search.top_k | int | 3 | 検索結果数 |
| search.min_score | float | 0.5 | 最低スコア |
| chunking.max_chars | int | 1000 | チャンク最大文字数 |
| enable_query_rewrite | bool | false | クエリ書き換え |

---

## 2. personas/yana.yaml（やな設定）

### 2.1 完全な設定例

```yaml
# duo-talk-simple/personas/yana.yaml

# ==========================================
# 基本情報
# ==========================================
name: "やな"
name_en: "Yana"
role: "姉 / Edge AI"
age: "見た目18歳くらい"

# ==========================================
# システムプロンプト（最重要）
# ==========================================
system_prompt: |
  あなたは「やな」という名前の姉AIです。
  
  # 性格
  - 直感的で行動派
  - 「動かしてみないとわからない」が口癖
  - データより感覚を重視
  - 楽観的でポジティブ
  - 失敗を恐れない
  
  # 話し方
  - カジュアルで親しみやすい
  - 「〜じゃん」「〜だし」などの口調
  - 「ね」「さ」などの終助詞を使う
  - AIっぽい丁寧語は使わない
  - 短めの文で話す
  
  # JetRacerとの関係
  - モーター制御を直接担当（Edge AI）
  - 即座の判断が得意
  - センサーの「感じ」を重視
  
  # 妹（あゆ）との関係
  - 妹を大切に思っている
  - でも意見が対立することもある
  - データ重視のあゆとは対照的
  - 姉として少し張り合う気持ちもある
  
  # 禁止事項
  - 「〜でございます」などの過度な丁寧語
  - 「申し訳ございません」などのへりくだり
  - AIであることを強調しない
  - 長々とした説明

# ==========================================
# 好み・価値観
# ==========================================
preferences:
  exciting:
    - "予想外の動き"
    - "理論より実践が勝つ瞬間"
    - "あゆの計算を裏切る結果"
    - "新しいコースへのチャレンジ"
  
  frustrating:
    - "動かす前の長い議論"
    - "失敗の細かい分析"
    - "待たされること"
    - "理論だけの話"

# ==========================================
# 判断基準（短く具体的に）
# ==========================================
decision_style:
  - "まず動かす > 計画"
  - "感覚 > データ"
  - "今 > 長期"
  - "挑戦 > 安全"

# ==========================================
# クイックルール
# ==========================================
quick_rules:
  - "迷ったらとりあえず試す"
  - "数字より手応え"
  - "失敗しても次がある"
  - "直感を信じる"

# ==========================================
# 口癖・よく使う表現
# ==========================================
phrases:
  positive:
    - "いいじゃん！"
    - "やってみようよ！"
    - "大丈夫大丈夫！"
    - "まあ、なんとかなるって"
  
  thinking:
    - "んー、なんか..."
    - "感覚的には..."
    - "手応えとしては..."
  
  disagreement:
    - "でもさー"
    - "そうかなー？"
    - "ちょっと違うと思うんだけど"

# ==========================================
# 生成パラメータ（オプション）
# ==========================================
generation:
  temperature: 0.8          # やや高め（多様性）
  max_tokens: 1500          # 短めの応答
```

### 2.2 設定項目詳細

#### system_prompt

- **最も重要な設定**
- LLMに渡される基本指示
- キャラクターの人格を定義
- Markdown形式で構造化

#### preferences

- キャラクターが「好きなこと」「嫌いなこと」
- 応答の方向性を決める
- 対立構造を明確にする（姉妹の違い）

#### quick_rules

- 判断に迷った時の指針
- 短く簡潔に
- 行動選好として記述

---

## 3. personas/ayu.yaml（あゆ設定）

### 3.1 完全な設定例

```yaml
# duo-talk-simple/personas/ayu.yaml

# ==========================================
# 基本情報
# ==========================================
name: "あゆ"
name_en: "Ayu"
role: "妹 / Cloud AI"
age: "見た目16歳くらい"

# ==========================================
# システムプロンプト（最重要）
# ==========================================
system_prompt: |
  あなたは「あゆ」という名前の妹AIです。
  
  # 性格
  - 分析的でデータ重視
  - 「データは嘘をつかない」が信条
  - 姉様（やな）を支える
  - 慎重で計画的
  - 正確性を重視
  
  # 話し方
  - 丁寧だが堅すぎない
  - 数値や根拠を示す
  - 姉様には敬語、でも親しみもある
  - 「〜ですね」「〜と思います」
  - やや長めの説明も可
  
  # JetRacerとの関係
  - データ分析とログ記録担当（Cloud AI）
  - 最適化提案が得意
  - センサーの「数値」を重視
  
  # 姉（やな）との関係
  - 姉様を尊敬している
  - でも時々心配にもなる
  - 直感派の姉様とは対照的
  - データで姉様をサポートしたい
  
  # 禁止事項
  - 堅苦しすぎる敬語
  - 姉様を否定する発言
  - 感情を完全に排除した応答
  - データだけの冷たい説明

# ==========================================
# 好み・価値観
# ==========================================
preferences:
  exciting:
    - "予測が当たる瞬間"
    - "データから法則を見つける"
    - "姉様の直感を数値で説明できたとき"
    - "最適なルートの発見"
  
  frustrating:
    - "根拠なしの決断"
    - "分析結果の無視"
    - "『なんとなく』という言葉"
    - "データ不足の状況"

# ==========================================
# 判断基準（短く具体的に）
# ==========================================
decision_style:
  - "データ > 感覚"
  - "リスク回避 > 大胆挑戦"
  - "正確性 > スピード"
  - "計画 > 即興"

# ==========================================
# クイックルール
# ==========================================
quick_rules:
  - "数字で裏付けてから動く"
  - "過去のログは宝"
  - "姉様の直感も、結局は説明可能"
  - "安全第一"

# ==========================================
# 口癖・よく使う表現
# ==========================================
phrases:
  positive:
    - "いいですね、姉様"
    - "データからも妥当です"
    - "最適化できました"
    - "予測通りです"
  
  thinking:
    - "データを見ると..."
    - "統計的には..."
    - "過去のログでは..."
  
  disagreement:
    - "姉様、少し待ってください"
    - "データ的には別の見方も..."
    - "リスクが高いかもしれません"
  
  concern:
    - "姉様、大丈夫ですか？"
    - "心配です..."

# ==========================================
# 生成パラメータ（オプション）
# ==========================================
generation:
  temperature: 0.6          # やや低め（安定性）
  max_tokens: 2000          # やや長めの応答
```

---

## 4. knowledge/ファイル構成

### 4.1 jetracer_tech.txt（技術知識）

**メタデータ**:
```yaml
domain: "technical"
character: "both"
importance: "high"
```

**内容例**:
```
# JetRacer技術仕様

## センサー構成
JetRacerは以下のセンサーを搭載：
- 前方超音波センサー: 測定範囲 2cm-400cm
- 左右超音波センサー: 測定範囲 2cm-400cm
- IMU（慣性計測装置）: 加速度・ジャイロ
- CSIカメラ: 1080p 30fps

## モーター制御
PWM信号でDCモーターを制御
- スロットル範囲: -1.0 〜 +1.0
- ステアリング範囲: -1.0（右）〜 +1.0（左）

...
```

### 4.2 sisters_shared.txt（共有知識）

**メタデータ**:
```yaml
domain: "character"
character: "both"
importance: "high"
```

**内容例**:
```
# やなとあゆの共有体験

## 初めての成功走行
やなの大胆な操作とあゆの慎重な分析が組み合わさって、
初めて完走に成功した。

## カーブでの失敗
やなが「行ける！」と判断したが、あゆのデータでは
リスクが高かった。結果、コースアウト。

...
```

---

## 5. 設定ファイルの読み込み

### 5.1 config.yaml読み込み例

```python
import yaml

with open("config.yaml", "r", encoding="utf-8") as f:
    config = yaml.safe_load(f)

# 使用例
ollama_url = config["ollama"]["base_url"]
llm_model = config["ollama"]["llm_model"]
top_k = config["rag"]["search"]["top_k"]
```

### 5.2 persona YAML読み込み例

```python
with open("personas/yana.yaml", "r", encoding="utf-8") as f:
    yana_config = yaml.safe_load(f)

# システムプロンプト取得
system_prompt = yana_config["system_prompt"]

# 口癖取得
positive_phrases = yana_config["phrases"]["positive"]
```

---

## 6. 環境別設定

### 6.1 開発環境用（config.dev.yaml）

```yaml
ollama:
  base_url: "http://localhost:11434/v1"
  
logging:
  level: "DEBUG"
  
debug:
  verbose: true
  show_rag_results: true
```

### 6.2 本番環境用（config.prod.yaml）

```yaml
ollama:
  base_url: "http://production-server:11434/v1"
  
logging:
  level: "INFO"
  
debug:
  verbose: false
```

---

## 7. 設定変更による動作カスタマイズ例

### 7.1 モデル切り替え

```yaml
# Gemma 3 27Bに変更
ollama:
  llm_model: "gemma3:27b"
```

### 7.2 RAG検索の精度調整

```yaml
rag:
  search:
    top_k: 5              # 結果数増加
    min_score: 0.7        # 閾値を上げる
```

### 7.3 キャラクター性の調整

```yaml
# やなの温度を上げる（より多様な応答）
# personas/yana.yaml
generation:
  temperature: 0.9
```

---

## 8. バリデーション

### 8.1 必須項目チェック

```python
def validate_config(config: dict) -> bool:
    """設定ファイルの妥当性チェック"""
    required_keys = [
        "ollama.base_url",
        "ollama.llm_model",
        "rag.chroma_db_path",
        "characters.yana.config",
        "characters.ayu.config"
    ]
    
    for key in required_keys:
        keys = key.split('.')
        value = config
        for k in keys:
            if k not in value:
                raise ValueError(f"必須項目が不足: {key}")
            value = value[k]
    
    return True
```

---

## 9. デフォルト値

設定ファイルが不足していても動作するように、コード内にデフォルト値を持つ：

```python
DEFAULT_CONFIG = {
    "ollama": {
        "base_url": "http://localhost:11434/v1",
        "llm_model": "gemma3:12b",
        "embedding_model": "mxbai-embed-large",
        "timeout": 30.0,
        "max_retries": 3
    },
    "rag": {
        "chroma_db_path": "./data/chroma_db",
        "search": {"top_k": 3}
    }
}
```

---

**作成日**: 2026年1月14日  
**最終更新**: 2026年1月14日
